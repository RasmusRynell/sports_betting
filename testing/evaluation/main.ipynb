{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "df2517d12cbacb86b38afffdc1f50cbbc41755439694c5330a7a1b4f6f24e217"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn import svm\r\n",
    "from sklearn.neural_network import MLPClassifier\r\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "# import roc_auc_score\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns; sns.set(font_scale=1.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "all_csvs = ['log_reg', 'Random_Forests', 'SVC-GridSearch', 'SVC']\r\n",
    "\r\n",
    "df = pd.DataFrame(index=['uniqueId'])\r\n",
    "for csv in all_csvs:\r\n",
    "    new_df = pd.read_csv(\"./{}.csv\".format(csv), sep=\";\")\r\n",
    "    new_df['date'] = pd.to_datetime(new_df['date'])\r\n",
    "    new_df['uniqueId'] = new_df['date'].astype(str) + \"-\" + new_df['player_id'].astype(str) + \"-\" + new_df['gamePk'].astype(str) + \"-\" + new_df['target'].astype(str)\r\n",
    "    new_df.sort_values(by=['uniqueId'], inplace=True)\r\n",
    "    new_df.columns = [str(col) + '_{}'.format(csv) if str(col) not in \\\r\n",
    "        ['uniqueId', 'player_id', 'gamePk', 'date', 'odds_under', 'odds_over', 'num_shots', 'answer', 'target'] else str(col) for col in new_df.columns]\r\n",
    "    new_df.set_index('uniqueId', inplace=True)\r\n",
    "    df = pd.concat([df, new_df], axis=1)\r\n",
    "df.dropna(inplace=True)\r\n",
    "df = df.loc[:,~df.columns.duplicated()]\r\n",
    "df['player_id'] = df['player_id'].astype(int)\r\n",
    "df['gamePk'] = df['gamePk'].astype(int)\r\n",
    "df['num_shots'] = df['num_shots'].astype(int)\r\n",
    "df['answer'] = df['answer'].astype(int)\r\n",
    "\r\n",
    "X = df.drop(['answer', 'odds_under', 'odds_over', 'num_shots', 'player_id', 'gamePk', 'date'], axis=1)\r\n",
    "y = pd.DataFrame({\"answer\": df['answer']})"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 22)\r\n",
    "X_train = X[:3500]\r\n",
    "X_test = X[3500:]\r\n",
    "y_train = y[:3500]\r\n",
    "y_test = y[3500:]\r\n",
    "\r\n",
    "sc = StandardScaler()\r\n",
    "X_train = sc.fit_transform(X_train)\r\n",
    "X_test = sc.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVM Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#clf = svm.SVC(C=1, gamma=0.001, probability=True) # Optimized\r\n",
    "clf = svm.SVC(C=0.525, gamma=0.0525, probability=True) # Generalized\r\n",
    "\r\n",
    "clf.fit(X_train, y_train.values.ravel())\r\n",
    "pred_clf = clf.predict(X_test)\r\n",
    "\r\n",
    "save_df = pd.DataFrame(df[3500:][['player_id', 'gamePk', 'date', 'odds_under', 'odds_over', 'num_shots', 'answer', 'target']])\r\n",
    "save_df[\"pred\"] = pred_clf\r\n",
    "pred_clf_prob = clf.predict_proba(X_test)\r\n",
    "save_df[\"proba_under\"] = [x[0] for x in pred_clf_prob]\r\n",
    "save_df[\"proba_over\"] = [x[1] for x in pred_clf_prob]\r\n",
    "\r\n",
    "\r\n",
    "save_df.to_csv('.\\my_g.csv', index=False, sep=\";\")\r\n",
    "\r\n",
    "print(classification_report(y_test, pred_clf))\r\n",
    "print(confusion_matrix(y_test, pred_clf))\r\n",
    "print(accuracy_score(y_test, pred_clf))\r\n",
    "\r\n",
    "# Print the feature importance\r\n",
    "#print(clf.feature_importances_)\r\n",
    "\r\n",
    "# Print AUC ROC score\r\n",
    "print(roc_auc_score(y_test, pred_clf))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.62      0.59       645\n",
      "           1       0.58      0.53      0.56       656\n",
      "\n",
      "    accuracy                           0.57      1301\n",
      "   macro avg       0.57      0.57      0.57      1301\n",
      "weighted avg       0.57      0.57      0.57      1301\n",
      "\n",
      "[[397 248]\n",
      " [307 349]]\n",
      "0.5734050730207533\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'SVC' object has no attribute 'feature_importances_'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d4dca544fc2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Print the feature importance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Print AUC ROC score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SVC' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_grid = { 'C': [0.575,0.55,0.525],\r\n",
    "               'gamma': [0.0555,0.055,0.0525]}\r\n",
    "\r\n",
    "clf2 = svm.SVC()\r\n",
    "rf_Grid = GridSearchCV(clf2, param_grid, n_jobs=7, scoring='accuracy',verbose=2)\r\n",
    "rf_Grid.fit(X_train,y_train.values.ravel())\r\n",
    "pred_clf2 = rf_Grid.predict(X_test)\r\n",
    "\r\n",
    "print(rf_Grid.best_params_)\r\n",
    "print(rf_Grid.score(X_test,y_test))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "{'C': 0.525, 'gamma': 0.0525}\n",
      "0.5734050730207533\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}